{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9331d092",
   "metadata": {},
   "source": [
    "# Q3: Data Wrangling\n",
    "\n",
    "**Phase 4:** Data Wrangling & Transformation  \n",
    "**Points: 9 points**\n",
    "\n",
    "**Focus:** Parse datetime columns, set datetime index, extract time-based features.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 2 ([`11/demo/02_wrangling_feature_engineering.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/02_wrangling_feature_engineering.ipynb)), Phase 4. Also see Lecture 09 (time series).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d790dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 196,559 cleaned records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matee\\AppData\\Local\\Temp\\ipykernel_2696\\4025637166.py:7: DtypeWarning: Columns (7,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('output/q2_cleaned_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load cleaned data from Q2\n",
    "df = pd.read_csv('output/q2_cleaned_data.csv')\n",
    "print(f\"Loaded {len(df):,} cleaned records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04686ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matee\\AppData\\Local\\Temp\\ipykernel_2696\\1246353083.py:11: DtypeWarning: Columns (7,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"output/q2_cleaned_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected datetime column: 'Measurement Timestamp'\n",
      "Q3 complete: Datetime features extracted and report saved to output/q3_datetime_info.txt\n"
     ]
    }
   ],
   "source": [
    "# --- Q3: Data Wrangling ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Load the cleaned data from Q2\n",
    "df = pd.read_csv(\"output/q2_cleaned_data.csv\")\n",
    "\n",
    "# --- Identify datetime column automatically ---\n",
    "datetime_col = None\n",
    "for candidate in df.columns:\n",
    "    if \"timestamp\" in candidate.lower() or \"date\" in candidate.lower() or \"time\" in candidate.lower():\n",
    "        datetime_col = candidate\n",
    "        break\n",
    "\n",
    "if datetime_col is None:\n",
    "    raise ValueError(\"No datetime column found in dataset.\")\n",
    "\n",
    "print(f\"Detected datetime column: '{datetime_col}'\")\n",
    "\n",
    "# --- Parse datetime and set index ---\n",
    "df[datetime_col] = pd.to_datetime(df[datetime_col], errors='coerce')\n",
    "df = df.set_index(datetime_col).sort_index()\n",
    "\n",
    "# --- Extract temporal features ---\n",
    "df['hour'] = df.index.hour\n",
    "df['day_of_week'] = df.index.dayofweek\n",
    "df['month'] = df.index.month\n",
    "\n",
    "# --- Save wrangled datasets ---\n",
    "df.to_csv(\"output/q3_wrangled_data.csv\")\n",
    "temporal_df = df.reset_index()[[datetime_col, 'hour', 'day_of_week', 'month']]\n",
    "temporal_df.to_csv(\"output/q3_temporal_features.csv\", index=False)\n",
    "\n",
    "# --- Compute and format date range info ---\n",
    "start_date = df.index.min()\n",
    "end_date = df.index.max()\n",
    "duration = end_date - start_date\n",
    "\n",
    "# Human-readable duration\n",
    "days = duration.days\n",
    "years = days // 365\n",
    "months = (days % 365) // 30\n",
    "remaining_days = (days % 365) % 30\n",
    "hours = duration.seconds // 3600\n",
    "\n",
    "# Create formatted string\n",
    "date_report = (\n",
    "    \"Date Range After Datetime Parsing:\\n\"\n",
    "    f\"Start: {start_date}\\n\"\n",
    "    f\"End: {end_date}\\n\"\n",
    "    f\"Total Duration: {years} years, {months} months, {remaining_days} days, {hours} hours\"\n",
    ")\n",
    "\n",
    "# Save to text file\n",
    "with open(\"output/q3_datetime_info.txt\", \"w\") as f:\n",
    "    f.write(date_report)\n",
    "\n",
    "print(\"Q3 complete: Datetime features extracted and report saved to output/q3_datetime_info.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d8451",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Parse datetime columns, set datetime index, and extract temporal features for time series analysis.\n",
    "\n",
    "**Time Series Note:** This dataset is time-series data (sensor readings over time), unlike the lecture's event-based taxi data. You'll work with a datetime index and extract temporal features (hour, day_of_week, month) that are essential for time series analysis. See **Lecture 09** for time series operations. Use pandas datetime index properties (`.hour`, `.dayofweek`, `.month`, etc.) to extract temporal features from your datetime index.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q3_wrangled_data.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Dataset with datetime index set\n",
    "**Requirements:**\n",
    "- Datetime column parsed using `pd.to_datetime()`\n",
    "- Datetime column set as index using `df.set_index()`\n",
    "- Index sorted chronologically using `df.sort_index()`\n",
    "- **When saving:** Reset index to save datetime as column: `df.reset_index().to_csv(..., index=False)`\n",
    "- All original columns preserved\n",
    "- **No extra index column** (save with `index=False`)\n",
    "\n",
    "### 2. `output/q3_temporal_features.csv`\n",
    "**Format:** CSV file\n",
    "**Required Columns (exact names):** Must include at minimum:\n",
    "- Original datetime column (e.g., `Measurement Timestamp` or `datetime`)\n",
    "- `hour` (integer, 0-23)\n",
    "- `day_of_week` (integer, 0=Monday, 6=Sunday)\n",
    "- `month` (integer, 1-12)\n",
    "\n",
    "**Optional but recommended:**\n",
    "- `year` (integer)\n",
    "- `day_name` (string, e.g., \"Monday\")\n",
    "- `is_weekend` (integer, 0 or 1)\n",
    "\n",
    "**Content:** DataFrame with datetime column and extracted temporal features\n",
    "**Requirements:**\n",
    "- At minimum: datetime column, `hour`, `day_of_week`, `month`\n",
    "- All values must be valid (no NaN in required columns)\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "**Example columns:**\n",
    "```csv\n",
    "Measurement Timestamp,hour,day_of_week,month,year,day_name,is_weekend\n",
    "2022-01-01 00:00:00,0,5,1,2022,Saturday,1\n",
    "2022-01-01 01:00:00,1,5,1,2022,Saturday,1\n",
    "...\n",
    "```\n",
    "\n",
    "### 3. `output/q3_datetime_info.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Date range information after datetime parsing\n",
    "**Required information:**\n",
    "- Start date (earliest datetime)\n",
    "- End date (latest datetime)\n",
    "- Total duration (optional but recommended)\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "Date Range After Datetime Parsing:\n",
    "Start: 2022-01-01 00:00:00\n",
    "End: 2027-09-15 07:00:00\n",
    "Total Duration: 5 years, 8 months, 14 days, 7 hours\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Datetime columns parsed correctly using `pd.to_datetime()`\n",
    "- [ ] Datetime index set using `df.set_index()`\n",
    "- [ ] Index sorted chronologically using `df.sort_index()`\n",
    "- [ ] Temporal features extracted: `hour`, `day_of_week`, `month` (minimum)\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Parse datetime** - Convert datetime column using `pd.to_datetime()`\n",
    "2. **Set datetime index** - Set as index and sort chronologically\n",
    "3. **Extract temporal features** - Use datetime index properties (`.hour`, `.dayofweek`, `.month`, etc.)\n",
    "4. **Save artifacts** - Remember to `reset_index()` before saving CSVs so the datetime becomes a column\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Datetime parsing:** What format is your datetime column? Use `pd.to_datetime()` with appropriate format string if needed: `pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')`\n",
    "- **Temporal features:** Extract at minimum: hour, day_of_week, month. Consider also: year, day_name, is_weekend, time_of_day categories. What makes sense for your analysis?\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q3, you should have:\n",
    "- [ ] Datetime columns parsed\n",
    "- [ ] Datetime index set and sorted\n",
    "- [ ] Temporal features extracted (at minimum: hour, day_of_week, month)\n",
    "- [ ] All 3 artifacts saved: `q3_wrangled_data.csv`, `q3_temporal_features.csv`, `q3_datetime_info.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q4_feature_engineering.md` for Feature Engineering.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
